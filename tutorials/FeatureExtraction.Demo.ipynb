{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tutorial is how to extract features using the acoustic feature extraction library. The tutorial will also document places where the library can be improved upon.\n",
    "\n",
    "The only dependency that requires installment is [librosa](https://github.com/librosa/librosa), an open-source acoustic and music feature extraction library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tables\n",
    "import json\n",
    "import music_feats.features.features as ft\n",
    "import numpy as np\n",
    "\n",
    "print \"done importing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nextPow(x):\n",
    "    \"\"\"Round input x to next highest power of 2.\"\"\"\n",
    "    return ceil(math.log(x, 2))\n",
    "def prevPow(x):\n",
    "    \"\"\"Round input x to next smallest power of 2.\"\"\"\n",
    "    return floor(math.log(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify which sound file to use\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'tests', 'data'))\n",
    "\n",
    "fname = \"Beethoven_Op027No1-01_003_20090916-SMD-norm.wav\" # sample wav file\n",
    "trname = 'sess_1_block_0_AN.report' # sample report file\n",
    "\n",
    "# some parameters for the feature extraction object. see docstring for full details\n",
    "sr = 44100 # sampling rate\n",
    "TR = 2.0045 # fMRI scanning sequence TR value\n",
    "\n",
    "# creatue features.Features object corresponding to that audio file\n",
    "feature_gen = ft.Features(os.path.join(data_dir, fname), TR=TR, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these are booleans used to indicate if window/hop (overlap) lengths used during feature extraction\n",
    "# should be rounded to the next highest or the next smallest power of 2\n",
    "use_prev = False\n",
    "use_next = False\n",
    "\n",
    "# the window and overlap amount to be used with short duration feature\n",
    "short_nfft = 2048 # ~50 ms granularity\n",
    "short_hop = int(short_nfft / 2) # ~25 ms overlap between windows\n",
    "\n",
    "# the window and overlap amount to be used with long duration features\n",
    "seconds = 1.34 # TODO: with later versions of librosa try adjusting this parameter (see below)\n",
    "long_nfft = int(seconds * sr) # convert the seconds to samples\n",
    "if use_prev:\n",
    "    long_nfft = 2**ft.prevPow(long_nfft) # ~0.743 sec\n",
    "elif use_next:\n",
    "    long_nfft = 2**ft.nextPow(long_nfft)\n",
    "long_hop = int(long_nfft / 2) # half overlap\n",
    "\n",
    "# binning spectrogram --> to be used with some of the long duration features\n",
    "seconds = 4 # rounded down to nearest power of 2 (w/ respect to sr=44100)\n",
    "\n",
    "# the intermediate step for FP and MPS\n",
    "FP_nfft = 512 # number from Pampalks PhD Thesis (2006)\n",
    "FP_hop = 512 # number from Pampalks PhD Thesis (2006); no overlap\n",
    "\n",
    "# CQT parameters\n",
    "cqt_hop = 1024\n",
    "cqt_seconds = 2.0 # chunk size prior to CQT; need to chunk\n",
    "n_bins = 120 # to match the tonotopic range\n",
    "bins_per_octave = 12 # to match the tonotopic range; 12 bands per octave\n",
    "fmin = 20 # minimum frequency used\n",
    "use_han = False # don't use the hanning window because librosa seems to window it anyway when creating frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short and long duration acoustic features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short and long duration features are based on [Alluri 2012](http://www.ncbi.nlm.nih.gov/pubmed/22116038) paper and the music information retrieval references cited within that paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract short duraction features\n",
    "# check docstrings for full list of arguments; will use the default values for now\n",
    "\n",
    "feature_gen.rms(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.temporalFlatness(hop_length=short_hop)\n",
    "feature_gen.zcr(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.spectralCentroid(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.spectralSpread(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.spectralFlatness(hop_length=short_hop)\n",
    "feature_gen.spectralContrast(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.spectralRolloff(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.mfcc(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.melspectrogram(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.stft(n_fft=short_nfft, hop_length=short_hop)\n",
    "feature_gen.CQT(cqt_hop=cqt_hop, seconds=cqt_seconds, n_bins=n_bins,\n",
    "                bins_per_octave=bins_per_octave, fmin=fmin, use_han=use_han)\n",
    "\n",
    "print 'done extracting short length features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Librosa v0.4.0 was used to develop the feature extraction library. At the time, long duration features were limited to be extracted over a 1.34 second window (even though the ideal window binning size might actually be 2-4ms according to the literature. This was a limitation in librosa's implementation of stft and should be explored with future versions of librosa. An alternative solution might be implementing one's own stft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract long duration features\n",
    "# check docstrings for full list of arguments; will use the default values for now\n",
    "\n",
    "feature_gen.chromagram(stft=True, n_fft=long_nfft, hop_length=long_hop, seconds=seconds, use_librosa=True)\n",
    "feature_gen.tonalCentroid(chroma=feature_gen.returnFeature('chroma'))\n",
    "feature_gen.tonality(n_fft=long_nfft, hop_length=long_hop, seconds=seconds, use_librosa=True)\n",
    "feature_gen.fluctuationPatterns(n_fft=FP_nfft, hop_length=FP_hop, seconds=seconds)\n",
    "feature_gen.fluctuationCentroid(n_fft=FP_nfft, hop_length=FP_hop, seconds=seconds)\n",
    "feature_gen.fluctuationFocus(n_fft=FP_nfft, hop_length=FP_hop, seconds=seconds)\n",
    "feature_gen.fluctuationEntropy(n_fft=FP_nfft, hop_length=FP_hop, seconds=seconds)\n",
    "\n",
    "print 'done extracting long length features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print all features extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print feature_gen.extractedFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some feature visualizations\n",
    "### RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.squeeze(feature_gen.returnFeature('RMS')))\n",
    "plt.title('RMS')\n",
    "plt.xlabel('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram (log scaled amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims = feature_gen.returnFeatureDim('S')\n",
    "print dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# flipping to have low frequencies at bottom and high frequencies at top\n",
    "plt.imshow(np.flipud(feature_gen.returnFeature('S')), aspect='auto')\n",
    "plt.xlabel('Time (window number)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.yticks(np.r_[0:1025:200][::-1], np.linspace(0, 22050, num=6))\n",
    "plt.title('Spectrogram (dB)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [MFCC](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is primarily relevant for vocal sound elements and not particularly informative for music and other non-vocal acoustic waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.flipud(feature_gen.returnFeature('MFCC')), aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.yticks([0,19][::-1], ['Low coeff', 'High coeff'])\n",
    "plt.title('Mel-frequency cepstral coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluctuation patterns (rhythmic patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluctuation patterns implementation based on:\n",
    "+ [Pampalk Thesis, 2006](http://www.ofai.at/~elias.pampalk/publications/pampalk06thesis.pdf)\n",
    "+ [Content-based Visualization and Organization of Music Archives](http://www.ifs.tuwien.ac.at/ifs/research/pub_pdf/pam_acmmm02.pdf)\n",
    "+ [Islands of Music: Analysis, Organization, and Visualization of Music Archives](http://www.ofai.at/~elias.pampalk/music/)\n",
    "+ [Fluctuation strength and temporal masking patterns of amplitude-modulated broadband noise](http://www.ncbi.nlm.nih.gov/pubmed/7142033)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo parameters are that we used 12 mel bands in the initial time-by-frequency representation, before computing the fluctuation patterns per frequency band. The maximum amplitude modulation frequency is 10Hz (also a parameter value that can be adjusted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims = feature_gen.returnFeature('FP').shape\n",
    "FP = feature_gen.returnFeature('FP')\n",
    "print dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure representation of the fluctuation patterns is a bit confusing at initial glance, but the break down is as such. The y-axis show the amplitude modulation frequencies for each of the frequency subbands that we took the fourier transform of. That is, for this example, each i-th continguous chunk of 360/12 (i.e, FP.shape[0]/num_mel_bands) corresponds to the fourier transform of i-th mel frequency subband of the melspectrogram, from which the fluctuation patterns are computed. The x-axis correponds to time segments that are 4 seconds long (reference **seconds** parameter defined above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "# flipping to have low frequencies at bottom and high frequencies at top\n",
    "plt.imshow(np.flipud(FP), aspect='auto', cmap='gray')\n",
    "plt.xlabel('Time segment number')\n",
    "plt.ylabel('Amplitude modulation per mel frequency band (Hz)')\n",
    "plt.yticks(np.r_[0:dims[0]:dims[0]/12][::-1], np.arange(1,13))\n",
    "plt.title('Fluctuation Patterns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, the mel frequency bands are enumerated. Below we visualize the fluctuation patterns correponding to one time segment (the first time segment). Follow the transformations done to have a better idea of what the representation is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshaping flunctuations for one time segment into the approrpriate size\n",
    "single_time = FP[:,0]\n",
    "print single_time.shape\n",
    "FP_single_time = single_time.reshape((12, dims[0]/12))\n",
    "print FP_single_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.flipud(FP_single_time.T), aspect='auto', cmap='gray')\n",
    "plt.xlabel('Mel-Frequency Band')\n",
    "plt.ylabel('Modulation Frequency (Hz)')\n",
    "plt.yticks(np.r_[0:30:5], list(np.linspace(5, 10, num=6))[::-1])\n",
    "plt.title('Fluctuation patterns for one time point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References used for implementation:\n",
    "+ [Tonal Description of Music Audio Signals](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.8192&rep=rep1&type=pdf)\n",
    "+ [Tonal Description of Polyphonic Audio for Music Content Processing](http://www.mtg.upf.edu/node/457)\n",
    "+ [Cognitive Foundations of Musical Pitch: A key-finding algorithm based on tonal hierarchies](http://www.utsc.utoronto.ca/~marksch/psyc56/Krumhansl%201990%20Ch%204.pdf)\n",
    "+ [Cognitive Foundations of Musical Pitch: Quantifying tonal hierarchies and key distances](http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195148367.001.0001/acprof-9780195148367-chapter-2)\n",
    "+ [What's Key for Key? The Krumhansl-Schmuckler Key-Finding Algorithm Reconsidered](http://www.jstor.org/stable/40285812?seq=1#page_scan_tab_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "keyTS = feature_gen.returnFeature('keyTimeSeries').squeeze()\n",
    "modeTS = feature_gen.returnFeature('modeTimeSeries').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keyMajor = np.ones(len(keyTS)) * -1\n",
    "keyMajor[modeTS == 0] = keyTS[modeTS == 0]\n",
    "\n",
    "keyMinor = np.ones(len(keyTS)) * -1\n",
    "keyMinor[modeTS == 1] = keyTS[modeTS == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(keyMajor, '+', label='major')\n",
    "plt.plot(keyMinor, '+', label='minor')\n",
    "plt.legend()\n",
    "plt.ylim([-0.25, 11.25])\n",
    "plt.yticks(np.arange(12), np.array(keys))\n",
    "plt.title('Tonality w/ modality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CQT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the library relies upon librosa's implementation of the constant-q transform, the following is the literature that explains the theory and implementation.\n",
    "\n",
    "+ [Calculation of the constant-q spectral transform](https://www.ee.columbia.edu/~dpwe/papers/Brown91-cqt.pdf)\n",
    "+ [An efficient algorithm for the calculation of a constant Q transform](http://academics.wellesley.edu/Physics/brown/pubs/effalgV92P2698-P2701.pdf)\n",
    "+ [The Constant Q Transform](http://doc.ml.tu-berlin.de/bbci/material/publications/Bla_constQ.pdf)\n",
    "+ [Constant-Q Transform Toolbox for Music Processing](http://iem.kug.ac.at/fileadmin/media/iem/projects/2010/smc10_schoerkhuber.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# flipping to have low frequencies at bottom and high frequencies at top\n",
    "plt.imshow(np.flipud(feature_gen.returnFeature('CQT')), aspect='auto')\n",
    "plt.xlabel('Time (window number)')\n",
    "plt.ylabel('Constant-Q Frequency Bands')\n",
    "plt.yticks(np.r_[0:120:20][::-1], np.linspace(20, 120, num=6, endpoint=True))\n",
    "plt.title('Constant-Q Transform (dB)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving has been left to use preference. Thus, the feature extraction object returns dictionaries containing the extracted features, the parameters used to extract these features, and the dimensions of each of the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features, featureParams, featureDims = feature_gen.saveFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print featureParams['RMS']\n",
    "print featureParams['CQT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hf = tables.open_file('sampleFeatures.hdf', mode='w', title='safe_file')\n",
    "# for vname, var in all_features.items():\n",
    "#     hf.create_array('/', vname, var)\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the featue params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('featureParams.json', 'w') as data_file:\n",
    "#     json.dump(featureParams, data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future directions and other remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly encouraged to use the docstrings provided in the library to your advantage. This is only a brief survey of the parameters and features that are available for manipulation.\n",
    "\n",
    "The library is currently v1, meaning that it is still a work in progress. Feel free to add to the library's functionality and/or address some of the TODO's in the source code (or even addressing the deprecation warnings above-during the feature extraction).\n",
    "\n",
    "Have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
